Topics in Philosophy of Psychology <small>with Professor Frances Egan</small>
=============================================================================

Syllabus
--------

### Course Description

The topic of the seminar is psychological explanation. We will focus on
two issues: (1) The role of representation in psychological explanation,
considering recent challenges – by (among others) proponents of
extended, embodied, and enactive cognition – to the traditional view
that psychological processes are to be understood as operations on
symbol structures. We will consider the requirements for a theoretical
construct to count as a representation, and whether there are any
distinctively mental representations. (2) The relation of psychology to
neuroscience, considering the recent challenge – by proponents of the
so-called 'new mechanism' view in philosophy of science – to the view
that psychological explanation of human cognitive capacities (in
particular, computational explanations of cognitive capacities) can be
constructed and confirmed independently of an account of how these
capacities are realized in the brain. The new mechanists argue that
genuine explanations of cognition are mechanistic explanations – they
must bear a transparent relationship to accounts of realizing neural
mechanisms.

### Readings

#### The role of representation in psychological explanation

-   The traditional view – strong representationalism
    -   Jerry Fodor. *Psychosemantics*, ch.1, Appendix
    -   Zenon Pylyshyn. "The Explanatory Role of Representation"

-   Implications and challenges
    -   David Kirsh. "When is Information Explicitly Represented?"
    -   William Ramsey. *Representation Reconsidered* (ch.3 and ch.4)

-   The challenge from extended, embodied, and enactive cognition
    -   Rodney Brooks. "Intelligence without Representation"
    -   John Haugeland. "Mind Embodied and Embedded"
    -   Clark & Chalmers. "The Extended Mind"
    -   Adams & Aizawa. "Defending the Bounds of Cognition"
    -   Robert Rupert. "Challenges to the Hypothesis of Extended
        Cognition"
    -   Lawrence Shapiro. *Embodied Cognition* (excerpt)
    -   Andy Clark. "An Embodied Cognitive Science?"
    -   Clark & Toribio. "Doing without Representing?"
    -   Anthony Chemero. "Anti-representationalism and the Dynamical
        Stance"
    -   Shaun Gallagher. "Are Minimal Representations Still
        Representations?"
    -   Daniel Hutto. "Radically Enactive Cognition in our Grasp"
    -   Mark Sprevak. "Fictionalism about Neural Representations"

#### The autonomy of psychology

-   The traditional view
    -   Jerry Fodor. "Special Sciences"
    -   Robert Cummins. "Functional Analysis"
    -   John Haugeland. "The Nature and Plausibility of Cognitivism"

-   The 'new mechanist' challenge
    -   David Michael Kaplan. "Explanation and Description in
        Computational Neuroscience"
    -   Piccinini & Craver. "Integrating Psychology and Neuroscience:
        Functional Analyses as Mechanism Sketches"
    -   Daniel Weiskopf. "Models and Mechanisms in Psychological
        Explanation"
    -   Frances Egan. "Function-Theoretic Explanation and Neural
        Mechanisms"

### Course Requirements

Students taking the course for credit will be expected to write a paper
due at the end of the semester. Papers must be on topics related to the
course materials; topics should be cleared with me beforehand. Graduate
students enrolled in the course will be expected to lead the discussion
of assigned materials for one session.

### Attendance

Attendance at the seminar is mandatory. You should let me know if you
have to miss a class.

### Course Objectives

Like any advanced philosophy graduate seminar this seminar aims to give
students an opportunity to explore a set of fundamental issues in depth
give students opportunities to further develop and hone their analytical
skills give students a chance to write and revise a major research paper
that will hopefully be interesting, original, and important provide
ample opportunities to further develop one's oral skills during
discussions

January 28th, 2013 <small>Reading</small>
-----------------------------------------

### Zenon Pylyshyn. "The Explanatory Role of Representation"

#### Introduction

-   The hardest puzzle is consciousness.
    -   Second hardest is *meaning*, which this work explains.
    -   Does *not* solve the puzzle of meaning.
    -   The author aims to **describe how the idea of the semantic
        content of representations is implicitly viewed within the field
        of cognitive science, and discuss why this view is
        justifiable**.

Representations
:   Generalizations stated over the contents of representations are not
    mere functional generalization in the usual sense.

Function generalizations
:   A theory that does not refer to physical properties of the
    particular system in question, only how it operates.

-   There will be a *representational level* and a *symbol-processing
    level*.

#### The Appeal to Representations

-   Law-like generalization and explanations can differ in several ways,
    consider:
    1.  A certain object accelerated at *a* meters per second per second
        because a steady force was applied that was equal to *ma*.
    2.  A certain neuron fired because a potential of *v* millivolts was
        applied along two of its sentries and that it had been inactive
        during the previous *t* milliseconds
    3.  A bit pattern of certain computer register came to have a
        particular configuration because of the particular contents
        present in the instruction register and the program counter, and
        because the system is wired according to a certain transfer
        protocol.
    4.  The computer printed numbers 2, 4, 6, because it started with
        the number 2 and added 2 repeatedly or because it applied the
        successor function repeatedly and double the value before
        printing.
    5.  The pedestrian dialed 911 because he believed it to be the
        emergency number and had recognized the urgent need for
        assistance.

-   Accounts (1), (2), and (3), all the terms refer to properties of
    objects within the closed system.[^1]
-   Accounts (4) and (6) are different in this important respect: Both
    make substantive reference to entities or properties that are not an
    intrinsic part of their state description, that is *numbers* and
    *need for assistance*.

> How is it possible for properties of the world to determine behavior
> when the properties are not causally related in the required sense to
> to the functional states of the system? --- **Brentano's problem**

-   The notion of representation is necessary only in the context of
    explanation.
-   Behavior is being caused by certain states of one's brain, and so
    mental states themselves are related to agent's actions.
-   Brain states are not causally connected in appropriate ways to
    walking or mountains.
    -   The relationship *is one of content*, a semantic, not causal,
        relationship.
        -   The notion of content is roughly that of what the states
            *are about*.

    -   Brain states cause certain movements. If these movements are
        view as members of equivalence classes described as "writing a
        sentence about walking in the Santa Cruz mountains" the brains
        states must be treated as embodying representations of these
        codes by certain rules.

-   Contrast the brain to a watch -- a watch's "behavior" is considered
    coextensive with the set of movements corresponding to the physical
    description of behavior.
    -   Two ways of explaining human behavior capture extremely
        different generalizations.

#### Representational and Functional Levels

-   This shows that **a *functional* description of mental processes is
    not enough, there must also be content**.

> If the content makes a difference to behavior, is it not also a
> functional difference?

-   To be in a certain representational state is to have a certain
    symbolic expression in some part of memory.
    -   The expression *encodes* the semantic interpretation and the
        combinatorial structure of the expression encodes the relation
        among the contents of the subexpressions, much as in the
        combinatorial system of predicate calculus.

-   The reason there must be symbolic codes is that they can enter in
    causal relations.[^2]
-   If there is a unique symbolic expression corresponding to each
    content, one might expect functional states and representational
    states to once again be one-to-one relation. Not so, because:
    1.  There may be codes with the same semantic content which are
        functionally but not semantically distinguishable.
    2.  Merely possessing a certain symbolic expression that encodes
        semantic content is insufficient to produce behavior.
        -   You need to *interpret* the symbols.

Semantic-level generalization
:   Generalizations expressible in terms of the semantic content of
    representations.

:   Newell calls this "knowledge-level."

Symbol-level generalizations
:   Generalizations expressible in terms of functional properties of the
    functional architecture.

#### Representational Content as Defining a Level of Description

-   We abandoned a biological vocabulary because of arbitrarily large
    disjunctions corresponding to processes like "thinking."
    -   Functional generalizations cannot be captured in a finite
        neurophysiological description.
    -   There is a vocabulary in between "*n* fired at *t* with *v*" and
        "He called 911 because he believed he was in an emergency."
        -   And it's *functional*.
        -   And it's in *semantic terms*.

-   "The principal of rationality is a major reason for our belief that
    a purely functional account will fail to capture certain
    generalizations, hence, that a distinct new level is required."

##### Levels and Constraints on Realizability

-   For a description, that description might be compatible with other
    levels.
    -   Newtons laws "are compatible with" biological taxonomy.

January 28th, 2014 <small>Seminar</small>
-----------------------------------------

### On representation

-   Advanced "beings" like us have evolved with our environment, this is
    with representation.
    -   These somehow causally affect behavior.
    -   This is an "inference to the best explanation."

-   To the degree which organisms can react to a changing circumstance
    causes the representation to change, and the changed representations
    change behavior.
-   Some people think that dynamic behavior requires
    representationalism.

Representation
:   A capacity of an organism.

Representation*s*
:   Concrete objects in the brain.

:   Some properties: - Physically realized. - They have causal powers,
    can have straightforward causal roles.

    -   They have content, they are meaningful.
        -   This requires a distinction between a vehicle of
            representation, they thing physically realized.

-   Vision resonates with the environment like a tuning fork. Gibson's
    theory of perception.
-   Our brains or us might have the structure for representations, but
    we can't "poke at" any representation.
-   One way that representat*ion* could get cached out is
    *dispositionally*.
    -   Some theories might posit capacities that are best characterized
        as *representational*.
    -   There might not be an isolable state at the computational level
        that's like, "There's the representation!"
        -   A real property of an organism, but diffuse.
        -   Like mass.

-   Many theories posit something analogous to "sentences in the head."
    -   But there are other models of cognition.
        -   Connectionist
        -   Dynamical

### Vehicle-side

Symbols
:   Little hooks on which you can hook meaning. Ripe for having content
    attributed to them, representation paradigmatically.

Connectionists models
:   Don't posit anything like "sentences in the head." The carriers of
    meaning are networks of nodes that are connected in various ways. Do
    get interpreted, but do individual nodes get interpreted? *That*
    node refers to red *in a network*.

:   Typically are not construed as a strong representational view.

Dynamical models
:   Model the behavior of the system over time.

-   What are the *vehicles* of meaning in non-symbol cognitive models?
    -   Is there anything in here that could be plausible construed as a
        representation?

-   In classical models, what the vehicles of representation are,
    symbols are hooks on which to hang interpretation. Waving red flags,
    interpret me.

### Content-side

-   Content has satisfaction conditions.

-   The problem of intentionality: How do mental states *get* their
    meaning? What is it about mental representations that given them
    their meaning or content.
    -   Public representation
        -   Public language content get their meaning by convention.
        -   Icons and images get meaning by their resemblance and
            convention.

    -   Private representation
        -   Some relation that isn't *already presuming* meaning or
            intentionality.
        -   The "meaning in the head" or "state of affairs" which it
            representations, **the naturalism semantics project**.
        -   "Complex causal relations" represented in my head.
        -   Teleological function of the brain, dealing with objects and
            properties I'm used, and my ancestors are, used to.

-   No one has be successful in naturalistic conditions on vehicle in
    the head having determinate content.
-   One constraint on all of these account is that mental states can not
    only *represent* but also *mis*represent.
    -   The contrast is with Grice's notion of natural meaning.
        -   The presence of smoke cannot misrepresent the presence of
            fire *unless* an agent misinterprets the smoke or something.

### Strong representationalism

Strong representationalism
:   Posits structure entities that have content.

:   Mental processes are defined over the structures.

-   An important issue: is there anything in non-representational views
    that could count as a vehicle.

Extended cognition
:   The mind extends into the environment in some sense.

:   The extended thesis is not centrally a critique of
    representationalism, but it does have theses that bring to bear on
    representationalism.

Embodied cognition
:   Human cognition is necessarily embedded, the mind-brain is the
    executive that controls the body.

Dynamical cognition
:   Cognition consists in a dynamical interaction between a subject and
    an environment, and it's wrong to characterize the interaction as
    contentful.

### Jerry Fodor's "Psychosemantics"

-   He gives two arguments for the view known as "representational
    theory of mind."
    -   Folk psychology is indispendable.
        -   The only way to vindicate it is if something like RTM is
            true.

    -   Eliminativism would be an absolute disaster.

-   The second is the striking parrallelism between trains of thought
    and inferences.
-   The argument focuses on prediction, the only way to get around in
    the world is to ask someone something and predict that, in general,
    you do what you say and similar elsewhere.
-   Intentional realism is the only appropriate attitude to take towards
    folk psychology.

Intentional realism
:   1.  They are semantically evaluable.
    2.  They have causal powers.
    3.  The implicit generalizations of commonsense belief/desire
        psychology are largely true of them.

RTM
:   The best hope for realizing intentional realism.

:   1.  For any organism O, and any attitude A toward the proposition P,
        there is a ('computational'/'functional') relation R and amental
        representation MP such that MP means that PI and O has A iff O 
        bears R to MP.
    2.  Mental processes are causal sequences of tokenings of mental 
        representations.

:   There are representation in a full-blooded sense.

-   If the LOT is true for propoisitonal attitudes, then the RTM is true
    because it's the weaker view.
    -   There's a big project on mental logic.

-   Oftentimes, people's reason doesn't follow logic.
    -   People will more often affirm the consequent, more common
        in mental reasoning than *modus tollens*.

-   "I believe there is beer in the refridgerator."
    -   What was causally efficaious was that I wanted beer
        and believed there was beer, so I got up to get beer.
    -   This is the "belief box."[^3]

-   There has to be a pretty good argument for the moving from
    property of one structure to the structure of the other.
    Specifically, they share semantics, but we need a good argument
    about syntax. Moving from the logical scheme to the empirical
    scheme.
    -   An argument *for this* is the tempurature case.

-   **We'll pick up next time with the Dennett counter-example.**

<!-- Accronymns -->

*[RTM]: Representational theory of mind

*[LOT]: Language of thought

<!-- Footnote -->

[^1]: I don't understand when you're "supposed to stop describing" for a
    closed system. I see that account (4) stops describing when the
    internal state of the computer comes to be required to continue
    explaining, but I don't understand why in account (3), supposedly
    "closed", you don't say that bits come to be charged via
    electricity, for instance.

    I think that even account (1), (2), and (3) really require an
    arbitrarily large conjunction of state description to be "closed."

[^2]: I want to know what a biological or neurological taxonomy of types
    would look like -- our ability to type artifacts and concepts seems
    sufficiently general that "anything can fit in the bin", that is we
    can store tokens of mountains and transcendental idealism -- if
    token couldn't be contained in any of our brain's possible types,
    would we be in a position to know?

[^3]: If we map the structural, syntatical, and semantical features of
    the way we *talk about* beliefs states and agents and doxastic 
    attitudes, the former is accesible to us and the latter is 
    inaccesible. But if we find a feature of the former we can reasonable
    map it to the latter.

    Often logic is called "the norms of believing." Does this pose a
    problem because logic is a norm of reasoning and we commonly don't
    reason well, via the affirming the consequent result, then maybe
    we can't move from one to the other.

    If we discover a mental structure which *conflicts* with logical
    structure, like for instance affirming the consequent being so
    common, should we affirm the consequent *more often* as a result?
    Alternatively, does it raise the perceived reliability of the
    seeming invalid (from a logical point-of-view) mental structure?
    If folk psychology is *generally valid* and we want to *vindicate*
    it, and actual, empirical mental structures follow invalid logical
    syntax, does that mean we want to vindicate invalid logical syntax
    too?


